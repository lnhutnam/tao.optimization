## Variational Optimization
1. Evolutionary Variational Optimization of Generative Models. [pdf](https://jmlr.org/papers/volume23/20-233/20-233.pdf) [code](https://github.com/tvlearn)
2. An Optimization-centric View on Bayes' Rule: Reviewing and Generalizing Variational Inference. [pdf](https://jmlr.org/papers/volume23/19-1047/19-1047.pdf) [code](https://github.com/JeremiasKnoblauch/GVIPublic)

## Non-convex Optimization
1. Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization. [pdf](https://jmlr.org/papers/volume23/20-924/20-924.pdf)
2. Stochastic Zeroth-Order Optimization under Nonstationarity and Nonconvexity. [pdf](https://jmlr.org/papers/volume23/19-750/19-750.pdf)
3. Riemannian Stochastic Proximal Gradient Methods for Nonsmooth Optimization over the Stiefel Manifold. [pdf](https://jmlr.org/papers/volume23/21-0314/21-0314.pdf)
4. Simple and Optimal Stochastic Gradient Methods for Nonsmooth Nonconvex Optimization. [pdf](https://jmlr.org/papers/volume23/21-0028/21-0028.pdf)
5. On Constraints in First-Order Optimization: A View from Non-Smooth Dynamical Systems. [pdf](https://jmlr.org/papers/volume23/21-0798/21-0798.pdf) [code](https://github.com/michaemu/OnConstraintsInFirstOrderOptimization.git)
6. Oracle Complexity in Nonsmooth Nonconvex Optimization. [pdf](https://jmlr.org/papers/volume23/21-1507/21-1507.pdf)

## Convex Optimization
1. Variance Reduced EXTRA and DIGing and Their Optimal Acceleration for Strongly Convex Decentralized Optimization. [pdf](https://jmlr.org/papers/volume23/20-1130/20-1130.pdf)
2. Stochastic subgradient for composite convex optimization with functional constraints. [pdf](https://jmlr.org/papers/volume23/21-1062/21-1062.pdf)

## Convergence
1. Extensions to the Proximal Distance Method of Constrained Optimization. [pdf](https://jmlr.org/papers/volume23/20-964/20-964.pdf) [code](https://github.com/alanderos91/ProximalDistanceAlgorithms.jl)
2. When is the Convergence Time of Langevin Algorithms Dimension Independent? A Composite Optimization Viewpoint. [pdf](https://jmlr.org/papers/volume23/21-1489/21-1489.pdf)
3. A proof of convergence for the gradient descent optimization method with random initializations in the training of neural networks with ReLU activation for piecewise linear target functions. [pdf](https://jmlr.org/papers/volume23/21-0962/21-0962.pdf)

## Approximation
1. Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks. [pdf](https://jmlr.org/papers/volume23/21-0368/21-0368.pdf)

## Tensor Completion
1. Provable Tensor-Train Format Tensor Completion by Riemannian Optimization. [pdf](https://jmlr.org/papers/volume23/21-1138/21-1138.pdf)
